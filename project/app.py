import re
import asyncio
import contextvars
import uuid
import itertools
import geopandas as gpd
import numpy as np
import pandas as pd
import time
import copy
import json

from IPython.display import display, Markdown
from scripts.flatten import flatten
from scripts.merge_dict import merge_dict
# from scripts.stream_output import stream_output_graph
from scripts.time_travel import get_state_by_config, get_states
from scripts.file_op import fileop
from scripts.time_travel import print_state
from scripts.workflow_struct import struct_agent
from scripts.convert import convert
from scripts.time_travel import update_state_by_config
from project.utils.result_merge import merge_delete_infos_json
from project.utils.decor import TaskMeta, register_method
from project.utils.task_type_schema import examples, TaskTypeRouter
from langchain_redis import RedisChatMessageHistory

class TestAgent:
    def __init__(self, **kwargs):
        # å¤–éƒ¨å˜é‡
        self.graphs = kwargs.get('graphs', None)
        self.merge_result = kwargs.get('merge_result', merge_delete_infos_json)
        self.order_list = kwargs.get('order_list', [])
        self.count = kwargs.get('count', 999)
        self.configs = kwargs.get('configs') if kwargs.get('configs') and kwargs.get('configs')[0] else []
        self.mode = kwargs.get('mode', 'fastapi')
        
        # å†…éƒ¨å˜é‡
        self._result_saver = self.ConversationContext(self)
        self._task_collection = self.TaskCollection(self)._method_map
        self._task_results_queue = asyncio.Queue()
        self._error_ctx = contextvars.ContextVar('error_ctx')
        self._task_ctx = contextvars.ContextVar('task_ctx')
        self._handlers: dict[str, callable] = {}
        self._active_workers = set()  # ä¿å­˜æ´»è·ƒ worker åç¨‹
        self._MAX_WORKERS = 10
        self._TIMEOUT = 240
        
        # fastapi
        self._message_queue = kwargs.get('message_queue', [])  # SSE
        self._task_connections = kwargs.get('task_connections', [])  # WebSocket
        self._task_id = kwargs.get('task_id', '')
        self._task_status = kwargs.get('task_status', {})
        self._communication_mode = 'websocket'

        # redis
        self._redis_client = kwargs.get('redis_client', None)
        self._history_redis_ctx = contextvars.ContextVar('history_redis_ctx')
        
    async def main(self):
        task_inputs_queue = asyncio.Queue()
        error_ctx = []
        token_error = self._error_ctx.set(error_ctx)

        manager_task = asyncio.create_task(self.manager(task_inputs_queue))

        previous_time = time.time()
        await asyncio.create_task(self.boss(task_inputs_queue))  # ç­‰å¾…bossç”Ÿæˆå®Œæ¯•
        await task_inputs_queue.join()  # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ

        for active_worker in self._active_workers:  # æ˜¾å¼å–æ¶ˆæ‰€æœ‰ worker
            active_worker.cancel()
        await asyncio.gather(*self._active_workers, return_exceptions=True)

        manager_task.cancel()  # å…³é—­manager
        await asyncio.gather(manager_task, return_exceptions=True)  # ä¸ä¼šraiseæŠ¥é”™,ä½†ä¼šå…³é—­manager

        iteration_time = time.time() - previous_time
        print('='*50, f"ä»»åŠ¡ç»“æŸ", '='*50)
        print(f"âœ… è¯¥ä»»åŠ¡è€—æ—¶: {iteration_time:.8f} ç§’")
        await self.send_result(self._task_id, {
            "type": "done",
            "task_id": self._task_id,
            "task_name": self.order_list,
        })

        if self._error_ctx.get():  # æœ€åç»Ÿä¸€æ”¶é›†é”™è¯¯ä¿¡æ¯
            await self.send_result(self._task_id, "ğŸ“‹ Collected errors:")
            for err in self._error_ctx.get():
                await self.send_result(self._task_id, f"  â€¢ {err}")
        self._error_ctx.reset(token_error)

    async def manager(self, queue):
        sem = asyncio.Semaphore(self._MAX_WORKERS)
        while True:
            await asyncio.sleep(0.1)

            # å¦‚æœæœ‰ä»»åŠ¡å°šæœªè¢« getï¼Œå¹¶ä¸”è¿˜æœ‰ worker ç©ºä½
            needed_workers = queue.qsize()
            available_slots = self._MAX_WORKERS - len(self._active_workers)
            to_spawn = min(needed_workers, available_slots)

            for _ in range(to_spawn):
                task = asyncio.create_task(self.worker(queue, sem))
                self._active_workers.add(task)
                asyncio.create_task(self.remove_task_after_timeout(task))

    async def worker(self, queue, sem):
        async with sem:
            try:
                while True:
                    task_input = await queue.get()  # cancelåªæœ‰åœ¨æœ€åº•å±‚çš„awaitæ‰ä¼šæ•è·,è€Œè¿™ä¸ªawait

                    # ä»»åŠ¡ä¿¡æ¯
                    task_id = task_input.get('task_id', "unknown")
                    task_name = task_input.get('task_name', "unknown")
                    task_type = task_input.get('task_type', "unknown")
                    # task_type = await self._redis_client.hget(f"task:{task_id}", 'task_type')

                    # å‚æ•°ä¿¡æ¯
                    graph_input = json.loads(task_input.get('graph_input'))
                    config = json.loads(task_input.get('config'))

                    # ä»»åŠ¡å‡†å¤‡
                    # è·å–å½“å‰ä»»åŠ¡å¹¶ä¿®æ”¹åç§°
                    current_task = asyncio.current_task()
                    if current_task:  # ç¡®ä¿å½“å‰åœ¨ä»»åŠ¡ä¸Šä¸‹æ–‡ä¸­
                        current_task.set_name(task_name)
                        current_task.task_id = task_id
                    await self.send_result(self._task_id, {
                        "type": "init",
                        "task_id": task_id,
                        "task_name": task_name
                    })
                    await self.wait_for_connection(task_id)  # ç­‰å¾…å­ä»»åŠ¡è¿æ¥å»ºç«‹

                    # å¯¹è¯è®°å½•ä¿å­˜
                    self._history_redis_ctx.set(RedisChatMessageHistory(
                        session_id=task_id,
                        redis_url="redis://localhost:6379",
                        ttl=3600,  # Expire chat history after 1 hour
                        # index_name=f"task:{task_id}"
                    ))

                    try:
                        # ä»»åŠ¡æ‰§è¡Œ
                        previous_time = time.time()
                        state_output = await self._task_collection[task_type](
                            graph_input=graph_input,
                            graph_name=task_name,
                            config=config,
                        )
                        iteration_time = time.time() - previous_time
                        await self.send_result(self._task_id, f"âœ… {task_name} è€—æ—¶: {iteration_time:.8f} ç§’")

                        # ç»“æœä¿å­˜
                        self._task_ctx.set({
                            "task_id": task_id, 
                            "task_name": task_name, 
                            "task_type": task_type, 
                            "task_result": state_output,
                        })
                        if self.configs:
                            self._result_saver.update_history(task_id, task_name, state_output)  # æœ‰configsï¼Œè¿›å…¥æ›´æ–°æ¨¡å¼
                        else:
                            self._result_saver.add_history(task_id, task_name, state_output)  # æ— configsï¼Œè¿›å…¥è¿è¡Œæ¨¡å¼

                        # ä¸‹æ¸¸ä»»åŠ¡
                        result_merged = self.merge_all_results([state_output])
                        result_flattened = self.flatten_and_tag(result_merged)
                        self.downstream(result_flattened, task_name)
                    except Exception as e:
                        error = f"âŒ {task_name} Caught: {e}"
                        self._error_ctx.get().append(error)
                        print(error)
                        await self.send_result(self._task_id, error)
                    finally:
                        # ä¸è¦å…³é—­worker
                        await self.send_result(task_id, {
                            "type": "done",
                            "task_id": task_id,
                            "task_name": task_name,
                        })
                        queue.task_done()
            except asyncio.CancelledError:  # åªæœ‰åœ¨awaitçš„æ—¶å€™æ‰ä¼šæ•è·å¼‚å¸¸
                raise asyncio.CancelledError

    async def boss(self, queue):
        if self.configs:
            for config in self.configs:
                print("="*50, "part1", "="*50)
                task_type = await self._redis_client.hget(f"task:{config['configurable']['thread_id']}", 'task_type')
                graph = self.graphs[task_type]
                new_values = {"messages": [("user", self.order_list[0])]}
                new_config = update_state_by_config(graph, config, new_values)
                task_name = get_state_by_config(graph, new_config)['values']['messages'][0].content
                data = {
                    'task_id': config['configurable']['thread_id'],
                    'task_name': task_name,
                    'task_type': task_type,
                    'graph_input': json.dumps(None),
                    'config': convert(new_config)
                }
                print("="*50, "part2", "="*50)
                await queue.put(data)
        else:
            order_db = np.array(self.order_list)
            mask = np.array([True] * len(order_db))
            prompt = "è¯·æ ¹æ®ç”¨æˆ·è¾“å…¥çš„ä»»åŠ¡ï¼Œåˆ¤æ–­å…¶ä»»åŠ¡ç±»å‹"
            while np.sum(mask) > 0 and self.count > 0:
                self.count -= 1
                indices = next(iter(np.where(mask)[0].tolist()))
                mask[indices] = False
                order = order_db[indices].tolist()

                task_names = [seg.strip() for seg in re.split(r"[;ï¼›]", order) if seg.strip()]
                for task_name in task_names:
                    task_type_raw = await struct_agent(TaskTypeRouter, prompt, examples).ainvoke({'messages': [("user", task_name)]})

                    if not isinstance(task_type_raw, dict):
                        task_type_raw = json.loads(task_type_raw.model_dump_json())
                    task_type = task_type_raw['task_type']
                    task_id = str(uuid.uuid4())
                    data = {
                        'task_id': task_id,
                        'task_name': task_name,
                        'task_type': task_type,
                        'graph_input': convert({"messages": [("user", task_name)]}),
                        'config': convert({
                            "configurable": {
                                "thread_id": task_id
                            }
                        })
                    }
                    await queue.put(data)

                    await self._redis_client.hset(f"task:{task_id}", mapping=data)  # hashï¼Œå­˜å‚¨ç”¨æˆ·çŠ¶æ€ï¼ˆå¯å˜
                    # await self._redis_client.xadd(f'task_stream', {'status': 'init'})  # streamï¼Œæµå¼è®°å½•å˜æ›´äº‹ä»¶ï¼ˆä¸å¯å˜

    async def remove_task_after_timeout(self, task):
        try:
            await asyncio.wait_for(task, timeout=self._TIMEOUT)
        except asyncio.TimeoutError:
            print(f"Task {task.get_name()} timed out after {self._TIMEOUT} seconds")
            await self.send_result(task.task_id, {
                "type": "close",
                "task_id": task.task_id,
                "task_name": task.get_name(),
            })
            raise ValueError(f"â² {task.get_name()} è¶…æ—¶ï¼")
        finally:
            self._active_workers.discard(task)

    async def gather_tasks(self, tasks):
        try:
            responses = await asyncio.wait_for(asyncio.gather(*tasks, return_exceptions=True), timeout=self._TIMEOUT)  # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        except asyncio.TimeoutError:
            raise ValueError("â² ä»»åŠ¡è¶…æ—¶ï¼")

        result_list = []
        for task_obj, res in zip(tasks, responses):
            task_name = task_obj.get_name()
            if isinstance(res, Exception):
                # raise ValueError(f"[{task_name}] å‡ºé”™: {res}")
                await self.send_result(self._task_id, f"[{task_name}] å‡ºé”™: {res}")
            else:
                await self.send_result(self._task_id, f"[{task_name}] æˆåŠŸ")
                if self.configs:
                    self._result_saver.update_history(str(res[0]), task_name, res[1])
                else:
                    self._result_saver.add_history(str(res[0]), task_name, res[1])
                result_list.append(res[1])
        return result_list

    def merge_all_results(self, result_list):
        if self._task_ctx.get()['task_type']!='retrieve':
            result = {}
            for r in itertools.chain.from_iterable(result_list):
                result = self.merge_result(result, r)
            return result
        else:
            return 

    def flatten_and_tag(self, result):
        if self._task_ctx.get()['task_type']!='retrieve':
            teams = []
            if result.get('red') not in ['null', None]:
                teams.append(('çº¢æ–¹', result['red']))
            if result.get('blue') not in ['null', None]:
                teams.append(('è“æ–¹', result['blue']))

            d = {}
            old_len = 0
            for color, team in teams:
                for flat in flatten(team):
                    d = merge_dict(d, flat, color)
                d_team = d.get('team', [])
                d_team.extend([color] * (len(d[next(iter(d))]) - old_len))
                d['team'] = d_team
                old_len = len(d[next(iter(d))])
            return d
        else:
            return

    def downstream(self, d, order):
        task_type = self._task_ctx.get()['task_type']
        ## agent_main
        if task_type=='deploy':
            marker_kwds = {'radius':10, 'draggable':True, 'fill':True}
            def my_colormap(value):
                if value == 'è“æ–¹':
                    return "blue"
                elif value == 'çº¢æ–¹':
                    return "red"
                else:
                    return "green"
            gdf = gpd.GeoDataFrame(d, crs="EPSG:4326").sort_values(by='team', ignore_index=True, kind='stable')
            # clear_output()
            display(Markdown(f'## <p style="text-align: center;">**{order}**</p>'))
            display(gdf)
            display(gdf.explore(column='team', cmap=[my_colormap(value) for value in gdf['team'].unique()], marker_type='circle_marker', marker_kwds = marker_kwds, tooltip = ['team', 'name']))

        ## agent_locate
        elif task_type=='delete':
            self.send_result(self._task_id, f"\n==== å·²åˆ é™¤è£…å¤‡ ====")
            for name, id in zip(d['name'], d['id']):
                self.send_result(self._task_id, f"{name}, {id}")
        
        ## agent_retrieve
        elif task_type=='retrieve':
            task_name, task_id, task_result = self._task_ctx.get()['task_name'], self._task_ctx.get()['task_id'], self._task_ctx.get()['task_result']
            self.send_result(self._task_id, f"\n==== æ•°æ®åº“æ£€ç´¢ç»“æœ ====")
            self.send_result(self._task_id, f"{task_result}")

    async def wait_for_connection(self, task_id: str, timeout: float = 5.0):
        if self.mode == 'fastapi':
            for _ in range(int(timeout * 10)):  # 10 æ¬¡æ¯æ¬¡ 100msï¼Œæ€»å…±æœ€å¤šç­‰å¾… 5 ç§’
                if task_id in self._task_connections:
                    return
                await asyncio.sleep(0.1)
            raise TimeoutError("WebSocket not connected in time")

    async def print_state(self, task_id, state):
        message = state['values']['messages'][-1]
        content = message.pretty_repr()
        self._history_redis_ctx.get().add_message(message)

        await self.send_result(task_id, f'{content}\n')
        if len(state['values']) > 1:
            await self.send_result(task_id, '==å…¶ä»–å˜é‡==')
            rest_values = copy.deepcopy(state['values'])
            rest_values.pop('messages')
            await self.send_result(task_id, f'{json.dumps(rest_values, indent=4, ensure_ascii=False)}\n')

        try:
            node_name = next(iter(state['metadata']['writes']))
        except:
            node_name = 'human'
        if node_name == '__start__':  # å¼ºè¡Œçº æ­£ä¸€ä¸ªæœºåˆ¶bugï¼Œé—®é¢˜ä¸å¤§
            node_name = 'human'
        await self.send_result(task_id, f'==å½“å‰èŠ‚ç‚¹==\n{node_name}')

        await self.send_result(task_id, f'==å½“å‰config==\n{json.dumps({"configurable":state["config"]["configurable"]}, indent=4, ensure_ascii=False)}')

    async def send_result(self, task_id, result):
        if self.mode == 'jupyter':
            print(result)
        else:
            if self._communication_mode == 'sse':
                # SSE
                await self._message_queue.put(result.replace('\n', 'temp'))
            elif self._communication_mode == 'websocket':
                # WebSocket
                websockets = self._task_connections.get(task_id, [])  # ç”±äºæ²¡æœ‰äº‹å…ˆåˆ›å»ºå¥½sub_taskçš„é€šé“ï¼Œå› æ­¤è¿™é‡Œä¸ºç©º
                
                if websockets:
                    for ws in websockets:
                        try:
                            if isinstance(result, str):
                                await ws.send_text(result.replace('\n', 'temp'))
                            elif isinstance(result, dict):
                                await ws.send_json(result)
                        except:
                            pass

    class ConversationContext:
        def __init__(self, test_agent):
            self.test_agent = test_agent

            self._user_name = None
            self._history = pd.DataFrame(columns=['thread_id', 'task_name', 'task_result'])
            
        def add_history(self, thread_id, task_name, task_result):
            self._history.loc[len(self._history)] = [thread_id, task_name, task_result]
        def update_history(self, thread_id, task_name, task_result):
            self.add_history(thread_id, task_name, task_result)
            self._history.drop_duplicates(subset='thread_id', keep='last', inplace=True)
        def print(self):
            self.test_agent.send_result(self.test_agent._task_id, self._history.to_string(index=False))

    class TaskCollection(metaclass=TaskMeta):  # å…ƒç±»åªæ˜¯æ³¨å†Œäº†æœªç»‘å®šselfçš„æ–¹æ³•ï¼Œè¿˜éœ€æ‰‹åŠ¨å®ç°ç»‘å®šselfï¼ˆæœªç»‘å®šçš„è¯ç›´æ¥è°ƒç”¨ä¼šå¯¼è‡´ç¼ºå°‘selfï¼‰
        """å„ç§ä»»åŠ¡çš„é›†åˆç±»"""
        
        def __init__(self, test_agent):
            self.test_agent = test_agent

            # åˆå§‹åŒ–å·²ç»‘å®šçš„æ–¹æ³•æ³¨å†Œè¡¨
            self._method_map = {}
            
            # å°†æœªç»‘å®šçš„æ–¹æ³•ç»‘å®šåˆ°å½“å‰å®ä¾‹
            for label, method in self._unbound_method_map.items():
                self._method_map[label] = method.__get__(self, type(self))  # æ–¹æ³•æ˜¯æè¿°ç¬¦ï¼ˆdescriptorï¼‰ï¼Œmethod.__get__(self, type(self)) ç­‰ä»·äºlambda *args, **kwargs: method(self, *args, **kwargs)ï¼Œæ­¤æ—¶å°±ç»‘å®šäº†self


        @register_method('deploy')
        async def deploy_graph(self, **kwargs):
            graph_input = kwargs.get('graph_input', None)
            graph_name = kwargs.get('graph_name', 'MyGraph')
            config = kwargs.get('config', {
                "configurable": {
                    "thread_id": str(uuid.uuid4())
                }
            })

            state_output = await self.stream_output_graph(self.test_agent.graphs['deploy'], graph_input, config, graph_name)
            result = state_output.get('final_response')

            return result
        
        @register_method('delete')
        async def delete_graph(self, **kwargs):
            graph_input = kwargs.get('graph_input', None)
            graph_name = kwargs.get('graph_name', 'MyGraph')
            config = kwargs.get('config', {
                "configurable": {
                    "thread_id": str(uuid.uuid4())
                }
            })

            state_output = await self.stream_output_graph(self.test_agent.graphs['delete'], graph_input, config, graph_name)
            result = state_output.get('final_response')

            return result
        
        @register_method('retrieve')
        async def retrieve_graph(self, **kwargs):
            graph_input = kwargs.get('graph_input', None)
            graph_name = kwargs.get('graph_name', 'MyGraph')
            config = kwargs.get('config', {
                "configurable": {
                    "thread_id": str(uuid.uuid4())
                }
            })

            state_output = await self.stream_output_graph(self.test_agent.graphs['retrieve'], graph_input, config, graph_name)
            result = state_output.get('final_response')

            return result
        

        async def stream_output_graph(self, graph, graph_input, config, graph_name):
            turn = 0
            previous_time = time.time()
            async for node, state_raw in graph.astream(
                    graph_input,
                    subgraphs=True,
                    stream_mode='debug',
                    config=config
                ):
                    state = state_raw['payload']
                    # fileop.save_any_append(state, f'datasets/{self.test_agent.mode}/{graph_name[:5]}.py')

                    if not state.get('values', {}).get('messages', []):
                        continue

                    await self.test_agent.print_state(config['configurable']['thread_id'], state)

                    turn += 1
                    current_time = time.time()
                    iteration_time = current_time - previous_time
                    await self.test_agent.send_result(config['configurable']['thread_id'], f"==={graph_name}=== ç¬¬{turn}æ¬¡è¿è¡Œ\n {node} è€—æ—¶: {iteration_time:.8f} ç§’")
                    previous_time = current_time

            return state.get('values', {})